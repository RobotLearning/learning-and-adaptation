\documentclass[a4paper]{article}
\title{Hyperparameter Estimation in R}
\author{Okan Koc}
\usepackage{Sweave}
\begin{document}
\maketitle

\section{1D Estimation}
In this example we repeat the simple 1-D hyperparameter estimation experiment using R. 

\subsection{Zero-mean}
First we start by drawing a random function from a zero-mean Gaussian Process with a gaussian covariance function:	

\begin{Schunk}
\begin{Sinput}
> # R HYPERPARAMETER ESTIMATION EXPERIMENTS
> library(MASS)
> print('Maximum likelihood estimation of hyperparameters...')
\end{Sinput}
\begin{Soutput}
[1] "Maximum likelihood estimation of hyperparameters..."
\end{Soutput}
\begin{Sinput}
> # squared exponential covariance function handle
> ker <- function(x1,x2,p) {
+ 	distsq <- sum((x1-x2)^2)
+ 	(p[2]^2) * exp(-distsq/(2*(p[1]^2)))
+ }
> # handle for generating a covariance matrix
> kermat <- function(xs,ker,p) {
+ 	size <- length(xs)
+ 	mat <- matrix(0, nrow = size, ncol = size)
+ 	for (i in 1:size) {
+ 		for (j in 1:size) {
+ 			mat[i,j] <- ker(xs[i],xs[j],p)
+ 		}
+ 	}
+ 	mat
+ }
> # covariance function hyperparameters: 
> # length scale ell and scale sf
> ell <- 1/8; sf <- 1/2
> p <- c(ell, sf)
> # noise scale
> sn <- 0.05
> # inform the user
> s <- sprintf('Covariance hyperparameters are: ell = %f, sf = %f, sn = %f', ell, sf, sn)
> print(s)
\end{Sinput}
\begin{Soutput}
[1] "Covariance hyperparameters are: ell = 0.125000, sf = 0.500000, sn = 0.050000"
\end{Soutput}
\begin{Sinput}
> # GENERATE A ZERO-MEAN FUNCTION DRAWN FROM THE GP 
> n <- 50
> # input variable
> x <- seq(from = 0, to = 1, length.out = 50)
> # form the covariance matrix
> K <- kermat(x,ker,p)
> # mean values
> mu <- rep(0, n);
> y <- mvrnorm(n = 1, mu, Sigma = K, tol = 1e-6)
> # contaminate y
> y <- y + sn * rnorm(n,1)
> plot(x,y, main = 'Function values drawn from a kernel with known parameters')
> 
\end{Sinput}
\end{Schunk}
\includegraphics{estimation-001}
\\
We minimize the following likelihood function : 

\begin{Schunk}
\begin{Sinput}
> # negative log likelihood to minimize
> nll <- function(p) {
+ 	if (length(p) == 3) # no mean estimation
+ 		vec <- y - mu 
+ 	else 
+ 		vec <- y - p[4] * x - p[5] 
+ 	mat <- kermat(x,ker,p[1:2]) + (p[3]^2) * diag(n)
+ 	rhks <- vec %*% solve(mat,vec)
+ 	cplex <- 1/2 * log(abs(det(mat)))
+ 	nll <- rhks + cplex
+ 	nll
+ }
> 
\end{Sinput}
\end{Schunk}
using the \emph{optim} function in R. The optimization algorithm chosen is the~\emph{L-BFGS-B}, but \emph{CG}, i.e. conjugate gradient, can also be specified:

\begin{Schunk}
\begin{Sinput}
> # minimization
> ell0 <- runif(1); sf0 <- runif(1); sn0 <- runif(1)
> #out <- nlm(nll, p = c(ell0, sf0, sn0), hessian = FALSE)
> lb <- c(0.01,0.01,0.01)
> out <- optim(par = c(ell0,sf0,sn0), nll, gr = NULL, method = "L-BFGS-B", lower = lb)
> ell_est <- out$par[1]; sf_est <- out$par[2]; sn_est <- out$par[3]
> print('Zero-mean GP hyperparameters:')
\end{Sinput}
\begin{Soutput}
[1] "Zero-mean GP hyperparameters:"
\end{Soutput}
\begin{Sinput}
> s <- sprintf('ell = %f, sf = %f, sn = %f', ell_est, sf_est, sn_est)
> print(s)
\end{Sinput}
\begin{Soutput}
[1] "ell = 0.103025, sf = 0.465751, sn = 0.072276"
\end{Soutput}
\begin{Sinput}
> 
\end{Sinput}
\end{Schunk}
\subsection{Linear-mean}
We repeat the same procedure, this time with a linear mean added to the gaussian process.

\begin{Schunk}
\begin{Sinput}
> # REPEAT BY INCLUDING LINEAR MEAN
> slope <- 0.5; intercept <- 1
> s <- sprintf('Mean hyperparameters are: slope = %f, intercept = %f', slope, intercept)
> print(s)
\end{Sinput}
\begin{Soutput}
[1] "Mean hyperparameters are: slope = 0.500000, intercept = 1.000000"
\end{Soutput}
\begin{Sinput}
> mu2 <- slope * x + intercept
> y <- mvrnorm(n = 1, mu2, Sigma = K, tol = 1e-6)
> # contaminate y
> y <- y + sn * rnorm(n,1)
> # minimization
> ell0 <- runif(1); sf0 <- runif(1); sn0 <- runif(1)
> slope0 <- runif(1); intercept0 <- runif(1)
> lb <- c(0.01,0.01,0.01,-1,-1)
> out <- optim(par = c(ell0,sf0,sn0,slope0,intercept0), nll, gr = NULL, method = "L-BFGS-B", lower = lb)
> ell_est <- out$par[1]; sf_est <- out$par[2]; sn_est <- out$par[3]
> slope_est <- out$par[4]; intercept_est <- out$par[5]
> print('Covariance hyperparameters:')
\end{Sinput}
\begin{Soutput}
[1] "Covariance hyperparameters:"
\end{Soutput}
\begin{Sinput}
> s1 <- sprintf('ell = %f, sf = %f, sn = %f', ell_est, sf_est, sn_est)
> print(s1)
\end{Sinput}
\begin{Soutput}
[1] "ell = 0.115906, sf = 0.495959, sn = 0.079803"
\end{Soutput}
\begin{Sinput}
> print('Mean hyperparameters:')
\end{Sinput}
\begin{Soutput}
[1] "Mean hyperparameters:"
\end{Soutput}
\begin{Sinput}
> s2 <- sprintf('slope = %f, intercept = %f', slope_est, intercept_est)
> print(s2)
\end{Sinput}
\begin{Soutput}
[1] "slope = 0.465293, intercept = 1.475263"
\end{Soutput}
\begin{Sinput}
> 
\end{Sinput}
\end{Schunk}
\section{2D Estimation}

Here we do hyperparameter estimation using the geostatistics package \emph{geoR}. This package supplies the function \emph{likfit} for Maximum Likelihood (ML) and Restricted Maximum Likelihood (REML), so it is not necessary to provide a custom likelihood function.

\subsection{Zero-mean}
We first start by generating a 2D uniform mesh with 100 points:

\begin{Schunk}
\begin{Sinput}
> # R hyperparameter estimation experiments
> library(MASS)
> library(geoR)
> print('Maximum likelihood estimation of hyperparameters...')
\end{Sinput}
\begin{Soutput}
[1] "Maximum likelihood estimation of hyperparameters..."
\end{Soutput}
\begin{Sinput}
> # cov.spatial can be used also!
> # squared exponential covariance function handle
> ker <- function(x1,x2,p) {
+ 	mat <- diag(p[1:2])
+ 	mahalanobis_sq <- (x1-x2) %*% solve(mat,x1-x2)
+ 	(p[2]^2) * exp(-mahalanobis_sq) 
+ 	# we don't divide by two since geoR uses this form
+ }
> # handle for generating a covariance matrix
> kermat <- function(xs,ker,p) {
+ 	size <- length(xs[,1])
+ 	mat <- matrix(0, nrow = size, ncol = size)
+ 	for (i in 1:size) {
+ 		for (j in 1:size) {
+ 			mat[i,j] <- ker(xs[i,],xs[j,],p)
+ 		}
+ 	}
+ 	mat
+ }
> # 2D ESTIMATION WITH ZERO MEAN
> L <- c(0.2, 0.5); sf <- 1
> phi <- L[2]/L[1] # anisotropy ratio parameter 
> p <- c(L, sf)
> # noise scale
> sn <- 0.1
> # inform the user
> s <- sprintf('Covariance hyperparameters are: L = [%f, %f], sf = %f, sn = %f', L[1], L[2], sf, sn)
> print(s)
\end{Sinput}
\begin{Soutput}
[1] "Covariance hyperparameters are: L = [0.200000, 0.500000], sf = 1.000000, sn = 0.100000"
\end{Soutput}
\begin{Sinput}
> # generate the mesh of input points
> n <- 10
> x <- seq(from = 0, to = 1, length.out = n)
> xx <- matrix(rep.int(x, n), nrow = n, byrow = TRUE)
> xxx <- as.vector(xx)
> yy <- t(xx)
> yyy <- as.vector(yy)
> coords <- matrix(c(xxx,yyy), ncol = 2)
> # apparently we can use expand.grid instead!
> # coords <- expand.grid(x, x)
> 
\end{Sinput}
\end{Schunk}

Now we generate function values at these points:

\begin{Schunk}
\begin{Sinput}
> # generate the covariance matrix
> # form the covariance matrix
> K <- kermat(coords,ker,p)
> # mean values
> mu <- rep(0, n*n);
> data <- mvrnorm(n = 1, mu, Sigma = K, tol = 1e-6)
> # contaminate data
> data <- data + sn * rnorm(n*n,1)
> # plot y values
> data_mat <- data
> dim(data_mat) <- c(n,n)
> image(x,x,data_mat, main = 'Function values drawn from a kernel with known parameters')
> 
\end{Sinput}
\end{Schunk}
\includegraphics{estimation-006}
\\
Maximum likelihood fitting is performed to estimate the parameters. The package documentation claims that several initial values for the hyperparameters can be provided but the algorithm fails in this case.

\begin{Schunk}
\begin{Sinput}
> ## ML LIKELIHOOD FITTING 
> # using function 'likfit' from package 'geoR'
> sn0 <- seq(from = 0.01, to = 0.2, length = 10)
> L0 <- seq(from = 0, to = 1.1, length = 5) 
> sf0 <- seq(from = 0, to = 2.2, length = 5)
> psiR0 <- c(0,1,2,3)
> # a matrix can be used to provide several initial values
> par0 <- matrix(c(L0, sf0), ncol = 2)
> ml <- likfit(coords = coords, data = data, trend = "cte", 
+ 	 	fix.nugget = FALSE, nugget = 0.04,
+ 	 	ini.cov.pars = c(0.3, 0.5),
+ 	 	cov.model = "gaussian", 
+        	fix.psiA = TRUE, fix.psiR = FALSE, psiR = 2,
+ 	 	lik.method = "ML")
\end{Sinput}
\begin{Soutput}
kappa not used for the gaussian correlation function
---------------------------------------------------------------
likfit: likelihood maximisation using the function optim.
likfit: Use control() to pass additional
         arguments for the maximisation function.
        For further details see documentation for optim.
likfit: It is highly advisable to run this function several
        times with different initial values for the parameters.
likfit: WARNING: This step can be time demanding!
---------------------------------------------------------------
likfit: end of numerical maximisation.
\end{Soutput}
\begin{Sinput}
> # output the results
> print(summary(ml))
\end{Sinput}
\begin{Soutput}
Summary of the parameter estimation
-----------------------------------
Estimation method: maximum likelihood 

Parameters of the mean component (trend):
  beta 
0.5757 

Parameters of the spatial component:
   correlation function: gaussian
      (estimated) variance parameter sigmasq (partial sill) =  0.2724
      (estimated) cor. fct. parameter phi (range parameter)  =  0.5175
   anisotropy parameters:
      (fixed) anisotropy angle = 0  ( 0 degrees )
      (estimated) anisotropy ratio = 1.291

Parameter of the error component:
      (estimated) nugget =  0.0115

Transformation parameter:
      (fixed) Box-Cox parameter = 1 (no transformation)

Practical Range with cor=0.05 for asymptotic range: 0.8956796

Maximised Likelihood:
   log.L n.params      AIC      BIC 
 "50.36"      "5" "-90.71" "-77.69" 

non spatial model:
   log.L n.params      AIC      BIC 
"-58.67"      "2"  "121.3"  "126.6" 

Call:
likfit(coords = coords, data = data, trend = "cte", ini.cov.pars = c(0.3, 
    0.5), fix.nugget = FALSE, nugget = 0.04, fix.psiA = TRUE, 
    fix.psiR = FALSE, psiR = 2, cov.model = "gaussian", lik.method = "ML")
\end{Soutput}
\begin{Sinput}
> 
\end{Sinput}
\end{Schunk}

Nugget parameter $\tao$ corresponds to the standard deviation of the noise that contaminates the function values. Anisotropy length parameter $\phi_{R}$ corresponds to the ratio between the larger and the smaller length scale parameters $l_1$ and $l_2$, $\phi_{R} = l_2/l_1$. That is, in the 2D Automatic Relevance Determination (ARD) case, the matrix :

\begin{equation*}
\mathbf{X} = \left(
\begin{array}{ccc}
l_{1}^{2} & 0             \\
0             & l_{2}^{2} \\
\end{array} \right)
\end{equation*}

causes anisotropy in the gaussian kernel :\\

\begin{equation*}
k(x,x') = \sigma_f^2 \exp{(x-x')^{T}\mathbf{\Sigma}^{-1}(x-x')}
\end{equation*}

\subsection{Linear-mean}
In this case, we also a linear mean with intercept, i.e. a line of the form: $y = \beta_1 x_1 + \beta_2 x_2 + \beta_0$. This can be triggered in the \emph{likfit} function by specifying \emph{trend = 1st} as an argument.
Restricted likelihood (REML) method can be selected to estimate the \emph{Generalized Least Squares} estimates of the $\beta$ parameters as well as estimating the covariance hyperparameters.

\begin{Schunk}
\begin{Sinput}
> ## GENERATE FUNCTION VALUES WITH LINEAN MEAN WITH INTERCEPT
> slope <- c(0.5,1); intercept <- 1
> s <- sprintf('Mean hyperparameters are: slope = [%f, %f], intercept = %f', 
+               slope[1], slope[2], intercept)
> print(s)
\end{Sinput}
\begin{Soutput}
[1] "Mean hyperparameters are: slope = [0.500000, 1.000000], intercept = 1.000000"
\end{Soutput}
\begin{Sinput}
> mu2 <- coords %*% slope + intercept
> data2 <- mvrnorm(n = 1, mu2, Sigma = K, tol = 1e-6)
> # contaminate y
> data2 <- data2 + sn * rnorm(n*n,1)
> ## REML LIKELIHOOD FITTING
> sn0 <- seq(from = 0.01, to = 0.2, length = 5)
> L0 <- seq(from = 0.01, to = 1.1, length = 5) 
> sf0 <- seq(from = 0.01, to = 2.2, length = 5)
> psiR0 <- c(0,1,2,3)
> # a matrix can be used to provide several initial values
> par0 <- matrix(c(L0, sf0), ncol = 2)
> reml <- likfit(coords = coords, data = data2, trend = "1st", 
+ 	 	fix.nugget = FALSE, nugget = 0.04,
+ 	 	ini.cov.pars = c(0.3, 0.5),
+ 	 	cov.model = "gaussian", 
+        	fix.psiA = TRUE, fix.psiR = FALSE, psiR = 1.5,
+ 	 	lik.method = "REML")
\end{Sinput}
\begin{Soutput}
kappa not used for the gaussian correlation function
---------------------------------------------------------------
likfit: likelihood maximisation using the function optim.
likfit: Use control() to pass additional
         arguments for the maximisation function.
        For further details see documentation for optim.
likfit: It is highly advisable to run this function several
        times with different initial values for the parameters.
likfit: WARNING: This step can be time demanding!
---------------------------------------------------------------
likfit: end of numerical maximisation.
\end{Soutput}
\begin{Sinput}
> # output the results
> print(summary(reml))
\end{Sinput}
\begin{Soutput}
Summary of the parameter estimation
-----------------------------------
Estimation method: restricted maximum likelihood 

Parameters of the mean component (trend):
 beta0  beta1  beta2 
0.6203 0.6327 1.2035 

Parameters of the spatial component:
   correlation function: gaussian
      (estimated) variance parameter sigmasq (partial sill) =  0.0779
      (estimated) cor. fct. parameter phi (range parameter)  =  0.4017
   anisotropy parameters:
      (fixed) anisotropy angle = 0  ( 0 degrees )
      (estimated) anisotropy ratio = 1.562

Parameter of the error component:
      (estimated) nugget =  0.0079

Transformation parameter:
      (fixed) Box-Cox parameter = 1 (no transformation)

Practical Range with cor=0.05 for asymptotic range: 0.695214

Maximised Likelihood:
   log.L n.params      AIC      BIC 
 "75.48"      "7"   "-137" "-118.7" 

non spatial model:
   log.L n.params      AIC      BIC 
 "30.86"      "4" "-53.72"  "-43.3" 

Call:
likfit(coords = coords, data = data2, trend = "1st", ini.cov.pars = c(0.3, 
    0.5), fix.nugget = FALSE, nugget = 0.04, fix.psiA = TRUE, 
    fix.psiR = FALSE, psiR = 1.5, cov.model = "gaussian", lik.method = "REML")
\end{Soutput}
\begin{Sinput}
> 
\end{Sinput}
\end{Schunk}
\end{document}
